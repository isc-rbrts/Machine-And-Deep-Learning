{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76503901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import string\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from nltk.tokenize.sonority_sequencing import SyllableTokenizer\n",
    "from nltk import word_tokenize\n",
    "from nltk import TweetTokenizer\n",
    "st = SyllableTokenizer()\n",
    "tt = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ff9e71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5000\n",
    "LEARNING_RATE = 0.004\n",
    "LAYERS = 2\n",
    "HIDDEN_SIZE = 256\n",
    "SEQ_SIZE = 25\n",
    "PRINT_EVERY_ITR = 500\n",
    "TEMPERATURE = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "234eb89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b70d9f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert sonnets to data\n",
    "shakespeare = open('shakespeare.txt', 'r')\n",
    "sonnets = []\n",
    "\n",
    "line = shakespeare.readline()\n",
    "while line != \"\":\n",
    "    sonnet_number = int(line.strip('\\n'))\n",
    "    sonnet = \"\"\n",
    "    \n",
    "    while line != '\\n' and line != '':\n",
    "        line = shakespeare.readline()\n",
    "        sonnet += line\n",
    "    sonnets.append(sonnet.strip('\\n'))\n",
    "    \n",
    "    if line == '':\n",
    "        break\n",
    "    \n",
    "    spacer = shakespeare.readline()\n",
    "    line = shakespeare.readline() #read next number\n",
    "shakespeare.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54636c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert syllable dict file to dictionary\n",
    "syllable_dict_file = open('Syllable_dictionary.txt', 'r')\n",
    "syllable_dict = dict()\n",
    "\n",
    "\n",
    "line = syllable_dict_file.readline()\n",
    "while line != \"\":\n",
    "    word = \"\"\n",
    "    syllables = 0\n",
    "    alt_syllables = 0\n",
    "    end_syllables = 0\n",
    "    \n",
    "    elements = line.split()\n",
    "    word = str(elements[0])\n",
    "    \n",
    "    if len(elements) > 2:\n",
    "        if elements[1][0] == 'E':\n",
    "            end_syllables = int(elements[1][1])\n",
    "            syllables = int(elements[2])\n",
    "        elif elements[2][0] == 'E':\n",
    "            end_syllables = int(elements[2][1])\n",
    "            syllables = int(elements[1])\n",
    "        else:\n",
    "            syllables = int(elements[1])\n",
    "            alt_syllables = int(elements[2])\n",
    "    else:\n",
    "        syllables = int(elements[1])\n",
    "\n",
    "    syllable_dict.update({word: [syllables, alt_syllables, end_syllables]})\n",
    "    line = syllable_dict_file.readline()    \n",
    "    \n",
    "syllable_dict_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2fbf087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the sonnets into words\n",
    "all_sonnet_words = []\n",
    "for sonnet in sonnets:\n",
    "    lines = sonnet.split('\\n')\n",
    "    sonnet_lines = []\n",
    "    for line in lines:\n",
    "        sonnet_lines += tt.tokenize(line) + ['\\n']\n",
    "        \n",
    "    all_sonnet_words.append(sonnet_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bc19559",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = [',', '.', '?', '!', ':', '(', ')', ';', \"'\", '\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45520256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find words not accounted for by syllable dict\n",
    "to_remove = []\n",
    "\n",
    "for i, sonnet in enumerate(all_sonnet_words):\n",
    "    for j, word in enumerate(sonnet):\n",
    "        if word.lower() not in syllable_dict and word not in punctuation:\n",
    "            \n",
    "            #fix some edge cases that aren't in the syllable dictionary\n",
    "            if word.lower() in ['gainst', 'greeing', 'scaped', 'tis', 'twixt']:\n",
    "                to_remove.append((i, j-1))\n",
    "                sonnet[j] = \"'\" + word\n",
    "            elif word.lower() == 't':\n",
    "                to_remove.append((i, j+1))\n",
    "                sonnet[j] = 'to'\n",
    "            elif word.lower() == 'th':\n",
    "                to_remove.append((i, j+1))\n",
    "                sonnet[j] = word + 'e'\n",
    "\n",
    "for removal in to_remove[::-1]:\n",
    "    i, j = removal\n",
    "    all_sonnet_words[i].pop(j)\n",
    "\n",
    "#print words that aren't in the syllable dictionary to see if we missed any\n",
    "for i, sonnet in enumerate(all_sonnet_words):\n",
    "    for j, word in enumerate(sonnet):\n",
    "        if word.lower() not in syllable_dict and word not in punctuation:\n",
    "            print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "514327e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the words in the sonnets to syllables, adjusting for the shakespeare dictionary\n",
    "tokenized_sonnets = []\n",
    "\n",
    "for sonnet in all_sonnet_words:\n",
    "    tokenized_sonnet = []\n",
    "    for word in sonnet:\n",
    "        if word in punctuation:\n",
    "            if tokenized_sonnet[-1] not in punctuation:\n",
    "                tokenized_sonnet[-1] = word\n",
    "            else:\n",
    "                tokenized_sonnet += word\n",
    "        else:\n",
    "            syllablized = st.tokenize(word)\n",
    "            syllables = -1\n",
    "            if word.lower() in syllable_dict:\n",
    "                syllables = syllable_dict[word.lower()][0]\n",
    "\n",
    "                while syllables < len(syllablized):\n",
    "                    if word[-1] == 'e' or word[-1] == 's':\n",
    "                        syllablized = syllablized[:-2] + [syllablized[-2] + syllablized[-1]]\n",
    "                    elif len(syllablized) > 2:\n",
    "                        syllablized = [syllablized[0] + syllablized[1]] + syllablized[2:]\n",
    "                    else:\n",
    "                        syllablized = [syllablized[0] + syllablized[1]]\n",
    "                    \n",
    "            tokenized_sonnet += syllablized + [\" \"]\n",
    "            \n",
    "    tokenized_sonnets.append(tokenized_sonnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06fbcfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#account for all unique syllables\n",
    "corpus_syllables = set()\n",
    "\n",
    "for sonnet in tokenized_sonnets:\n",
    "    for syllable in sonnet:\n",
    "        corpus_syllables.add(syllable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e91a5190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create mapping for all unique syllables\n",
    "corpus_dictionary = dict()\n",
    "reverse_dict = dict()\n",
    "\n",
    "for i,syllable in enumerate(corpus_syllables):\n",
    "    corpus_dictionary.update({syllable: i})\n",
    "    reverse_dict.update({i: syllable})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd19d5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(corpus_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51a8a598",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, num_layers, output_size, hidden_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.rnn = nn.LSTM(hidden_size, hidden_size, num_layers)\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, input_seq, hidden_state):\n",
    "        embedding = self.embedding(input_seq)\n",
    "        output, hidden_state = self.rnn(embedding.unsqueeze(1), hidden_state)\n",
    "        output = self.decoder(output)\n",
    "        return output, (hidden_state[0].detach(), hidden_state[1].detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cd6b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toTensor(syllables):\n",
    "    tensor = torch.zeros(len(syllables)).long()\n",
    "    for i, syllable in enumerate(syllables):\n",
    "        tensor[i] = corpus_dictionary[syllable]\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c95ab73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRandomExample(data, sequence_size):\n",
    "    sonnet_index = random.randint(0, len(data) - 1)\n",
    "    sonnet = data[sonnet_index]\n",
    "    sonnet_position = random.randint(0, len(sonnet) - sequence_size)\n",
    "    seq = sonnet[sonnet_position : sonnet_position + sequence_size + 1]\n",
    "    input_seq = toTensor(seq[:-1])\n",
    "    target_seq = toTensor(seq[1:])\n",
    "    return input_seq, target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e550904d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size=vocab_size, num_layers=LAYERS, output_size=vocab_size, hidden_size=HIDDEN_SIZE).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7c4add5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning training\n",
      "Epoch: 500, Loss: 3.8124874877929686\n",
      "Epoch: 1000, Loss: 2.92393798828125\n",
      "Epoch: 1500, Loss: 3.281172180175781\n",
      "Epoch: 2000, Loss: 4.035428161621094\n",
      "Epoch: 2500, Loss: 3.21732666015625\n",
      "Epoch: 3000, Loss: 3.6085614013671874\n",
      "Epoch: 3500, Loss: 3.714349670410156\n",
      "Epoch: 4000, Loss: 3.7021466064453126\n",
      "Epoch: 4500, Loss: 3.2543179321289064\n",
      "Epoch: 5000, Loss: 2.953560791015625\n"
     ]
    }
   ],
   "source": [
    "print(\"Beginning training\")\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    input_seq, target_seq = getRandomExample(tokenized_sonnets, SEQ_SIZE)\n",
    "    hidden = torch.zeros(LAYERS, 1, HIDDEN_SIZE).to(device)\n",
    "    cell = torch.zeros(LAYERS, 1, HIDDEN_SIZE).to(device)\n",
    "    \n",
    "    model.zero_grad()\n",
    "    loss = 0\n",
    "    input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
    "    \n",
    "    for c in range(SEQ_SIZE):\n",
    "        output, (hidden, cell) = model(input_seq, (hidden, cell))\n",
    "        loss += loss_fn(torch.squeeze(output), torch.squeeze(target_seq))\n",
    "        \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss = loss.item() / SEQ_SIZE\n",
    "    \n",
    "    if epoch % PRINT_EVERY_ITR == 0:\n",
    "        print(f'Epoch: {epoch}, Loss: {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0b36f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sonnet generated with temperature: 1.5\n",
      "Shall I compare thee to a summer's day?\n",
      "It him best,dead still consmost darhes,goesnature were hast writetain\n",
      "Not taught thou our days,tiesjusiege astaintned death-sesnalatetaint!\n",
      "Unless grief to love,tatain flattance matage best\n",
      "Whate'tions have grant much,than flowers going,and thou frown if give,the two none.\n",
      "Is whom of gay,\n",
      "Against otcause know,a Under,abunby charial?\n",
      "Ere to not discahehold,by thou end,if thou deep sertant need gait,it tells-beus ,\n",
      "Yet temfore hateselfhing proritate,to changetyranrest prime cast,\n",
      "Unless aputy's moun valate may,from jolThy satekens.I my costling bier baall mourn pleaty,as thy waigarden'riner's strong,from of wake,ter hues,then summer life lory,some datresscy  sumsumbe raspeak,though sight?\n",
      "Or hard\n",
      "Save truthsrigly memtish cheer;of,where two the news;\n",
      "and estan hooks?\n",
      "How faigoingly saufinds:\n",
      "\n",
      "Sonnet generated with temperature: 0.75\n",
      "Shall I compare thee to a summer's day?\n",
      "Which find too do away,\n",
      "But love I age with self of nature's my exvesy of better)\n",
      "And maglect thee will\n",
      "Where life is their looks all on thy love of make glory days up day,\n",
      "Intend of thy self,\n",
      "But face of all will sorken,\n",
      "Which all my A Unless me that stand is on thy self,\n",
      "Beaking of lines,the in thy prepear,\n",
      "When be in eneter a each friend,\n",
      "And on else my hate?\n",
      "But thy resuring on should I store,\n",
      "Which be to my wastes love,\n",
      "To love in hand for,\n",
      "\n",
      "Sonnet generated with temperature: 0.5\n",
      "Shall I compare thee to a summer's day?\n",
      "And repair and thy self to the shalloture and base thy self to my rich the comclition a self his all be that is thou well,\n",
      "That my best of her thou a In thou not see,\n",
      "And as thy you I nature of thy strength a dear is the pen the love,\n",
      "To love a thy feeter my beacelrywhere,\n",
      "But for my know of the detant in a pleasure,\n",
      "To in a put the so to thy rich one,\n",
      "But a it but not his of the lips in my not my for the comuty's of thee to thy she with I thou and their every and the hadst to in thy so face,\n",
      "That the summer my I their that I with I self not can hast thee my true,\n",
      "And love the upon be so look of one,\n",
      "In as my you be to a he as the in my the love a in thy my can the earth is my thou I see worth with of be and as a we my deaful me I of all my least of me the find,\n",
      "But thou love of love I my love thou will in the self a love,\n",
      "And I glass no in hapson this of in thy the be breathe of a look of you that of all,\n",
      "And in my and beader control,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperatures = [1.5, 0.75, 0.5]\n",
    "\n",
    "for temp in temperatures:\n",
    "    prompt = [\"Shall\", \" \", \"I\", \" \", \"com\", \"pare\", \" \", \"thee\", \" \", \"to\", \" \", \"a\", \" \", \"sum\", \"mer's\", \" \", \"day\", \"?\", \"\\n\"]\n",
    "    generated_string = \"\"\n",
    "    for s in prompt:\n",
    "        generated_string += s\n",
    "    lines = 1\n",
    "\n",
    "    prompt = toTensor(prompt)\n",
    "    hidden = torch.zeros(LAYERS, 1, HIDDEN_SIZE).to(device)\n",
    "    cell = torch.zeros(LAYERS, 1, HIDDEN_SIZE).to(device)\n",
    "\n",
    "    for c in range(len(prompt) - 1):\n",
    "        _, (hidden, cell) = model(prompt[c].view(1).to(device), (hidden, cell))\n",
    "\n",
    "    prime_char = prompt[-1]\n",
    "\n",
    "    while lines < 14:\n",
    "        output, (hidden, cell) = model(prime_char.view(1).to(device), (hidden, cell))\n",
    "        distribution = F.softmax(output / temp, dim=2)\n",
    "        syllable_id = torch.multinomial(distribution[0], 1)[0][0].item()\n",
    "        next_syllable = reverse_dict[syllable_id]\n",
    "        generated_string += str(next_syllable)\n",
    "        prime_char = toTensor([next_syllable])\n",
    "        if next_syllable == '\\n':\n",
    "            lines += 1\n",
    "    \n",
    "    print(f'Sonnet generated with temperature: {temp}')\n",
    "    print(generated_string)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
